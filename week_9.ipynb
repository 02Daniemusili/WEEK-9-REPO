{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week 9",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/12345997/WEEK-9-REPO/blob/main/week_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLG2VTrnTvYL"
      },
      "source": [
        "## 1. Defining the Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XecOwPNorl2W"
      },
      "source": [
        "### a) Specifying the Data Analytic Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ozBnKfehSAw"
      },
      "source": [
        "> Predict predict whether a message is spam or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4wfHZwQrs-t"
      },
      "source": [
        "### b) Defining the Metric for Success\n",
        "to be able to carry out data analysis and modelling using various algorithm to check the possibility that a message is a spam or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9BPYqunry97"
      },
      "source": [
        "### c) Understanding the context \n",
        "spam are used by companies in dvertising their products and for that resason one needs to filter out whether a message is a spam or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMRBJ7zr9HD"
      },
      "source": [
        "### d) Recording the Experimental Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSGyg6kWsBUl"
      },
      "source": [
        "### e) Data Relevance\n",
        "the dataset we are provided with was relevant for our analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUNbvIvnT7ep"
      },
      "source": [
        "## 2. Reading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJn2KjW-WMlG"
      },
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from tabulate import tabulate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZlXyCnO_vE9"
      },
      "source": [
        "#Read data from a csv to a dataframe\n",
        "data = pd.read_csv(\"/content/spambase.data\", names=list(range(0,58)))\n",
        "#data = df.values.tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58VBzkIrRboz"
      },
      "source": [
        "#Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yaTGVk9Rpjx",
        "outputId": "d572411f-48dc-4095-9e43-961acebebb1b"
      },
      "source": [
        "#checking for null values\n",
        "data.isnull().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     False\n",
              "1     False\n",
              "2     False\n",
              "3     False\n",
              "4     False\n",
              "5     False\n",
              "6     False\n",
              "7     False\n",
              "8     False\n",
              "9     False\n",
              "10    False\n",
              "11    False\n",
              "12    False\n",
              "13    False\n",
              "14    False\n",
              "15    False\n",
              "16    False\n",
              "17    False\n",
              "18    False\n",
              "19    False\n",
              "20    False\n",
              "21    False\n",
              "22    False\n",
              "23    False\n",
              "24    False\n",
              "25    False\n",
              "26    False\n",
              "27    False\n",
              "28    False\n",
              "29    False\n",
              "30    False\n",
              "31    False\n",
              "32    False\n",
              "33    False\n",
              "34    False\n",
              "35    False\n",
              "36    False\n",
              "37    False\n",
              "38    False\n",
              "39    False\n",
              "40    False\n",
              "41    False\n",
              "42    False\n",
              "43    False\n",
              "44    False\n",
              "45    False\n",
              "46    False\n",
              "47    False\n",
              "48    False\n",
              "49    False\n",
              "50    False\n",
              "51    False\n",
              "52    False\n",
              "53    False\n",
              "54    False\n",
              "55    False\n",
              "56    False\n",
              "57    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNpjLjo9R06W",
        "outputId": "cf9c6944-0a21-4481-a8ba-6651e854ef0e"
      },
      "source": [
        "data.duplicated().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "391"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSf-zKv5Tcq7"
      },
      "source": [
        " data.drop_duplicates(subset=None, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVORIuKERUCl"
      },
      "source": [
        "#Exploratory data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTbdjSrhVIiT"
      },
      "source": [
        "## . Implementing the Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhoPAWLCROE5"
      },
      "source": [
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, 57].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQdHvQ6qCTi3"
      },
      "source": [
        "# after performing feature extraction from our data, it is time to build our model. \n",
        "#  start by splitting our data into training and test sets with a 20% test set and 80% as training set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5FHypAEHbYi"
      },
      "source": [
        "#initializing the naive_bayes therorem\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB().fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnRbIKJJJs4D",
        "outputId": "9a37aa5a-75b0-4f40-9f2b-ae668e38ac67"
      },
      "source": [
        "# Once we have put together our classifier, we can evaluate its performance in the testing set\n",
        "predicted = model.predict(X_test)\n",
        "print(np.mean(predicted == y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7947882736156352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5JTYJraKHl8"
      },
      "source": [
        "thus our model gives an predicted accuracy value of 79.47% which is acceptable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVKY3NrqL5sH"
      },
      "source": [
        "# after performing feature extraction from our data, it is time to build our model. \n",
        "#  start by splitting our data into training and test sets with a 20% test set and 80% as training set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lST2KJwdMr27"
      },
      "source": [
        "#initializing the naive_bayes therorem\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB().fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzwuQtCFMwUe",
        "outputId": "0c928703-0626-41f0-cc28-feac14078d29"
      },
      "source": [
        "# Once we have put together our classifier, we can evaluate its performance in the testing set\n",
        "predicted = model.predict(X_test)\n",
        "print(np.mean(predicted == y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7921795800144823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8nHqAipPe_b"
      },
      "source": [
        "thus our model gives an predicted accuracy value of 79.21% which is acceptable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df4ITINvPjrr"
      },
      "source": [
        "# after performing feature extraction from our data, it is time to build our model. \n",
        "#  start by splitting our data into training and test sets with a 20% test set and 80% as training set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVpHZv5kPsCZ"
      },
      "source": [
        "#initializing the naive_bayes therorem\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB().fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F7y57mMPxQs",
        "outputId": "9899a1ac-b370-424e-c2df-d29e1ad6dd6e"
      },
      "source": [
        "# Once we have put together our classifier, we can evaluate its performance in the testing set\n",
        "predicted = model.predict(X_test)\n",
        "print(np.mean(predicted == y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7941336230309615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP98zaCpQNsf"
      },
      "source": [
        "with 40% test set the accuracy of the models predictions is 79.41% which is nearly the saame as the predicted accuracy with 20% test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ2G4ZPDVOXE"
      },
      "source": [
        "## 8. Challenging the solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3x3SXZ4XT_L"
      },
      "source": [
        "# Reviewing the Solution \n",
        "#\n",
        "the difference between the three models is small hence the model can be said to be worth for our training dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrmHVMVsVS--"
      },
      "source": [
        "## 9. Follow up questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pth2qSWhuBIy"
      },
      "source": [
        "> At this point, we can refine our question or collect new data, all in an iterative process to get at the truth.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPQviDmNtta8"
      },
      "source": [
        "### a). Did we have the right data? **yes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjFHK1CKty7o"
      },
      "source": [
        "### b). Do we need other data to answer our question? **yes, so the we increase the accuracy of our prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSsicSdvt4Zs"
      },
      "source": [
        "### c). Did we have the right question? **yes**"
      ]
    }
  ]
}